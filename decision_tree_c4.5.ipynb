{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pattern Recognition Work\n",
    "                                                                                         \n",
    "- Implement the C4.5 Decision Tree algorithm to classify the database provided\n",
    "- In the C4.5 algorithm, you must use entropy (information gain) as a criterion for choosing the nodes\n",
    "- Pruning is not necessary\n",
    "- Randomly divide data between training and testing.\n",
    "- You must choose the attributes that you find most convenient\n",
    "- At least 4 attributes must be used.\n",
    "\n",
    "\n",
    "                                                                                    Alanna Maria Machado Alves Paiva\n",
    "                                                                                           Ananda KÃ¡ren Barros Nobre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import operator\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classe</th>\n",
       "      <th>Alcool</th>\n",
       "      <th>Acido malico</th>\n",
       "      <th>Cinza</th>\n",
       "      <th>Alcalinidade da cinza</th>\n",
       "      <th>Magnesio</th>\n",
       "      <th>Fenois totais</th>\n",
       "      <th>Flavonoides</th>\n",
       "      <th>Fenois nao flavonoides</th>\n",
       "      <th>Proantocianidinas</th>\n",
       "      <th>Intensidade da cor</th>\n",
       "      <th>Matiz</th>\n",
       "      <th>OD280/OD315 de vinhos diluidos</th>\n",
       "      <th>Prolina</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Classe  Alcool  Acido malico  Cinza  Alcalinidade da cinza  Magnesio  \\\n",
       "0       1   14.23          1.71   2.43                   15.6       127   \n",
       "1       1   13.20          1.78   2.14                   11.2       100   \n",
       "2       1   13.16          2.36   2.67                   18.6       101   \n",
       "3       1   14.37          1.95   2.50                   16.8       113   \n",
       "4       1   13.24          2.59   2.87                   21.0       118   \n",
       "\n",
       "   Fenois totais  Flavonoides  Fenois nao flavonoides  Proantocianidinas  \\\n",
       "0           2.80         3.06                    0.28               2.29   \n",
       "1           2.65         2.76                    0.26               1.28   \n",
       "2           2.80         3.24                    0.30               2.81   \n",
       "3           3.85         3.49                    0.24               2.18   \n",
       "4           2.80         2.69                    0.39               1.82   \n",
       "\n",
       "   Intensidade da cor  Matiz  OD280/OD315 de vinhos diluidos  Prolina  \n",
       "0                5.64   1.04                            3.92     1065  \n",
       "1                4.38   1.05                            3.40     1050  \n",
       "2                5.68   1.03                            3.17     1185  \n",
       "3                7.80   0.86                            3.45     1480  \n",
       "4                4.32   1.04                            2.93      735  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('wine.csv', header=None)\n",
    "columns = ['Classe', 'Alcool', 'Acido malico', 'Cinza', 'Alcalinidade da cinza','Magnesio',\n",
    "           'Fenois totais', 'Flavonoides','Fenois nao flavonoides','Proantocianidinas',\n",
    "           'Intensidade da cor','Matiz','OD280/OD315 de vinhos diluidos','Prolina']\n",
    "df.columns = columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Classifiers \n",
    "#### 2.1 Implement the classifier: C4.5 (Decision Tree)\n",
    "- Should use entropy (information gain) as a criterion for choosing nodes.\n",
    "- You do not need to perform pruning.\n",
    "- You should choose the attributes you find most convenient.\n",
    "- You should use at least 4 attributes.\n",
    "- Do not use ready-made Matlab/Python functions for C4.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attribute choices\n",
    "As stated in the work, the columns given already have the attributes to be chosen, so I chose the first four, which are:\n",
    "\n",
    "* Alcohol\n",
    "* Malic Acid \n",
    "* Gray\n",
    "* Ash Alkalinity\n",
    "\n",
    "There is no problem in choosing other attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classe</th>\n",
       "      <th>Alcool</th>\n",
       "      <th>Acido malico</th>\n",
       "      <th>Cinza</th>\n",
       "      <th>Alcalinidade da cinza</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13.05</td>\n",
       "      <td>1.65</td>\n",
       "      <td>2.55</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>12.25</td>\n",
       "      <td>1.73</td>\n",
       "      <td>2.12</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>11.84</td>\n",
       "      <td>2.89</td>\n",
       "      <td>2.23</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>14.10</td>\n",
       "      <td>2.02</td>\n",
       "      <td>2.40</td>\n",
       "      <td>18.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>1</td>\n",
       "      <td>14.20</td>\n",
       "      <td>1.76</td>\n",
       "      <td>2.45</td>\n",
       "      <td>15.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2</td>\n",
       "      <td>13.03</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.71</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>1</td>\n",
       "      <td>14.06</td>\n",
       "      <td>1.63</td>\n",
       "      <td>2.28</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>2</td>\n",
       "      <td>11.41</td>\n",
       "      <td>0.74</td>\n",
       "      <td>2.50</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130 rows Ã 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Classe  Alcool  Acido malico  Cinza  Alcalinidade da cinza\n",
       "0         1   13.05          1.65   2.55                   18.0\n",
       "1         1   13.24          2.59   2.87                   21.0\n",
       "2         2   12.25          1.73   2.12                   19.0\n",
       "3         2   11.84          2.89   2.23                   18.0\n",
       "4         1   14.10          2.02   2.40                   18.8\n",
       "..      ...     ...           ...    ...                    ...\n",
       "125       1   14.37          1.95   2.50                   16.8\n",
       "126       1   14.20          1.76   2.45                   15.2\n",
       "127       2   13.03          0.90   1.71                   16.0\n",
       "128       1   14.06          1.63   2.28                   16.0\n",
       "129       2   11.41          0.74   2.50                   21.0\n",
       "\n",
       "[130 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Separa os 4 atributos\n",
    "atributos = pd.DataFrame({})\n",
    "atributos['Classe']  = df['Classe'] \n",
    "atributos[df.iloc[:,1].name]  = df.iloc[:,1]\n",
    "atributos[df.iloc[:,2].name]  = df.iloc[:,2]\n",
    "atributos[df.iloc[:,3].name]  = df.iloc[:,3]\n",
    "atributos[df.iloc[:,4].name]  = df.iloc[:,4]\n",
    "atributos\n",
    "\n",
    "\n",
    "# We will remove a class \n",
    "atributos.drop(atributos.query('Classe==3').index,inplace=True)\n",
    "\n",
    "# Sorteia a nova tabela por linha\n",
    "atributos = atributos.sample(frac=1).reset_index(drop=True)\n",
    "display(atributos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FunÃ§Ã£o que calcula a entropia dos dados\n",
    "def entropy(df_label):\n",
    "    classes,class_counts = np.unique(df_label,return_counts = True)\n",
    "    entropy_value = np.sum([(-class_counts[i]/np.sum(class_counts))*np.log2(class_counts[i]/np.sum(class_counts)) \n",
    "    for i in range(len(classes))])\n",
    "    return entropy_value\n",
    "\n",
    "# FunÃ§Ã£o que calcula a acurÃ¡cia \n",
    "def accuracy(original, predicted):\n",
    "    correct = 0\n",
    "    for i in range(len(original)):\n",
    "        if original[i] == predicted[i]:\n",
    "            correct += 1\n",
    "    return correct / float(len(original)) * 100.0\n",
    "\n",
    "# FunÃ§Ã£o que verifica e retorna a classe mais comum \n",
    "def most_common_label(y):\n",
    "    most_common = Counter(y).most_common(1)\n",
    "    return most_common[0][0]\n",
    "\n",
    "# FunÃ§Ã£o que retorna os Ã­ndices dos filhos\n",
    "def split(X_column, split_thresh):\n",
    "    column = np.array(X_column)\n",
    "    left_idxs = np.argwhere(column <= split_thresh).flatten()\n",
    "    right_idxs = np.argwhere(column > split_thresh).flatten()\n",
    "    return left_idxs, right_idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing Decision Trees (C4.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(\n",
    "    self, feature=None, threshold=None, left=None, right=None, *, value=None\n",
    "    ):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "\n",
    "    def is_leaf_node(self):\n",
    "        return self.value is not None\n",
    "\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, min_samples_split=2, max_depth=100):\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.root = None\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.root = self.grow(X_train, y_train)\n",
    "\n",
    "    def predict(self, X_train):\n",
    "        return np.array([self.traverse_tree(x, self.root) for x in X_train])\n",
    "\n",
    "    def grow(self, X_train, y_train, depth=0):\n",
    "            n_samples, n_features = X_train.shape\n",
    "            n_labels = len(np.unique(y_train))\n",
    "            \n",
    "            # CritÃ©rios de parada\n",
    "            if (\n",
    "                depth >= self.max_depth\n",
    "                or n_labels == 1\n",
    "                or n_samples < self.min_samples_split\n",
    "            ):\n",
    "                leaf_value = most_common_label(y_train)\n",
    "                return Node(value=leaf_value)\n",
    "\n",
    "            # Calcula o melhor limiar para cada atributo\n",
    "            gains, idx = list(), -1\n",
    "            \n",
    "            for i in X_train.T: \n",
    "                idx += 1\n",
    "                gains.append(self.chose_threshold(X_train[:, idx], y_train, idx))\n",
    "\n",
    "            # Armazena o melhor limiar e o atributo a qual ele pertence \n",
    "            gains = sorted(gains)\n",
    "            best_thresh, best_feat = gains[0][1], gains[0][2]\n",
    "    \n",
    "            # Divide os dados pelo limiar e cria nÃ³s filhos resultantes da divisÃ£o\n",
    "            left_idxs, right_idxs = split(X_train[:, best_feat], best_thresh)\n",
    "            left = self.grow(X_train[left_idxs, :], y_train[left_idxs], depth + 1)\n",
    "            right = self.grow(X_train[right_idxs, :], y_train[right_idxs], depth + 1)\n",
    "            return Node(best_feat, best_thresh, left, right)\n",
    "    \n",
    "    def chose_threshold(self, atributo, classe, idx):\n",
    "        label_ord, val_ord = np.array(classe), np.array(atributo)\n",
    "        \n",
    "        N = len(label_ord)\n",
    "        lbl_ant = label_ord[0] \n",
    "        limiares = list()\n",
    "\n",
    "        # Calcula os limiares\n",
    "        for i in range(N-1):\n",
    "            lbl = label_ord[i+1]\n",
    "            if(lbl != lbl_ant):\n",
    "                limiares.append((val_ord[i+1] + val_ord[i]) / 2)\n",
    "\n",
    "            lbl_ant = lbl\n",
    "\n",
    "        # Divide dados em dois grupos, atraves do valor do limiar\n",
    "        Nlimiares = len(limiares)\n",
    "        mean_entropy = []\n",
    "        \n",
    "        # Cada limiar divide os dados em dois grupos\n",
    "        for i in range(Nlimiares):\n",
    "            limiar = limiares[i]\n",
    "\n",
    "            gr1, gr2, grp_entropy1, grp_entropy2 = list(), list(), list(), list()\n",
    "            for j in range(N):\n",
    "                if (val_ord[j] < limiar ):\n",
    "                    gr1.append(label_ord[j])\n",
    "                else: \n",
    "                    gr2.append(label_ord[j])\n",
    "            # Calcula e armazena a entropia dos grupos\n",
    "            grp_entropy1.append(entropy(gr1)), grp_entropy2.append(entropy(gr2))\n",
    "            # Calcula e entropia mÃ©dia dos grupos\n",
    "            mean_entropy.append([(a + b) / 2 for a, b in zip(grp_entropy1, grp_entropy2)])\n",
    "        # Armazena a menor entropia e o seu indice\n",
    "        index, value = min(enumerate(mean_entropy), key=operator.itemgetter(1))\n",
    "        return value, limiares[index], idx\n",
    "\n",
    "\n",
    "    def traverse_tree(self, x, node):\n",
    "        if node.is_leaf_node():\n",
    "            return node.value\n",
    "        if x[node.feature] <= node.threshold:\n",
    "            return self.traverse_tree(x, node.left)\n",
    "        return self.traverse_tree(x, node.right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3)The C4.5 descision tree algorithm (Make 10 achievements )\n",
    "\n",
    "#### a) Realization:\n",
    "- Randomly divide data between training and testing. (Ex: 80% for training, 20% for testing)\n",
    "- Build the model with the training data\n",
    "- Check the accuracy (hit rate) of the model (test). \n",
    "b) Statistics:\n",
    "- Calculate the average hit rate of the 10 realizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.15%\n",
      "Accuracy: 96.15%\n",
      "Accuracy: 96.15%\n",
      "Accuracy: 96.15%\n",
      "Accuracy: 96.15%\n",
      "Accuracy: 96.15%\n",
      "Accuracy: 96.15%\n",
      "Accuracy: 96.15%\n",
      "Accuracy: 96.15%\n",
      "Accuracy: 96.15%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "for i in range(10):\n",
    "\n",
    "    X, y = np.array(atributos.drop('Classe', axis=1)), np.array(atributos['Classe']) \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "    clf = DecisionTree(max_depth=10)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy(y_test, y_pred)\n",
    "\n",
    "    scores = []\n",
    "    scores.append(acc)\n",
    "\n",
    "    print(f'Accuracy: %.2f%%' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Statistics:\n",
    "- Calculate the average hit rate of the 10 runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 96.15%\n"
     ]
    }
   ],
   "source": [
    "mean = (sum(scores)/float(len(scores)))\n",
    "print(f'Mean Accuracy: %.2f%%' % mean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
